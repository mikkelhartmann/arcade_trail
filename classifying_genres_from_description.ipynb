{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classifying game genres based on game descriptions\n",
    "The goal is to use short (170 character) description of games to classify them as 1 og 31 game genres. The idea is that it should be possible to get a broad overview of what kind og game it is by reading the description. Let's have a few example:\n",
    "\n",
    ">a game of exploration and survival in an epic fantasy setting\n",
    "\n",
    ">A physics based game with 100 levels of challenging fun\n",
    "\n",
    ">Welcome to the next-generation of open-world gaming\n",
    "\n",
    ">The long awaited second expansion to Blizzards critically acclaimed RTS\n",
    "\n",
    ">A Pay2Win business model simulator(adventure) that exposes the tricks online game businessmen use to maximize monetizatio\n",
    "\n",
    "This illustrages some of the benifits and challanges of the dataset. Let's have a look at the 31 genres:\n",
    "\n",
    "1. Action\n",
    "2. Indie\n",
    "3. Strategy\n",
    "4. Early Access\n",
    "5. Free to Play\n",
    "6. Massively Multiplayer\n",
    "7. RPG\n",
    "8. Adventure\n",
    "9. Casual\n",
    "10. Simulation\n",
    "11. Racing\n",
    "12. Sports\n",
    "13. **Audio Production**\n",
    "14. **Utilities**\n",
    "15. **Video Production**\n",
    "16. **Education**\n",
    "17. **Design & Illustration**\n",
    "18. **Web Publishing**\n",
    "19. **Photo Editing**\n",
    "20. **Software Training**\n",
    "21. **Animation & Modeling**\n",
    "24. Puzzle\n",
    "25. Platformer\n",
    "26. Survival\n",
    "27. Shooter\n",
    "28. Horror\n",
    "29. Sandbox\n",
    "30. **Music**\n",
    "31. Fighting\n",
    "32. Hidden Objects\n",
    "33. **Accounting**\n",
    "\n",
    "Quite a lot of these (11 ~ 1/3) are not actually games. That is because Steam sell application that are not games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To do this we will be using the sklearn python package. It is an extremely useful machine learning package that will allow us to build a powerfull classifier in just a couple of lines. The disadvantage of this package is that it makes it possible to build, very quickly, something that you don't understand. At best it is a problem solver, at worst it is a black box generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Getting and loading the data\n",
    "The raw data are psql dumps from the homepage www.arcatetrail.com. The site is not longer active. \n",
    "\n",
    "The raw data is loaded using custom loading functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/game_titles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4715698af607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReccomenderSystem\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreading_titles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/game_titles.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgenres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_games\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreading_votes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/game_genres.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaglines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreading_taglines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/game_tagline.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Storage/Documents/projects/arcade_trail/src/ReccomenderSystem.py\u001b[0m in \u001b[0;36mreading_titles\u001b[0;34m(path_to_data)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Defining the function that loads game titles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreading_titles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mnumberOfLines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/game_titles.csv'"
     ]
    }
   ],
   "source": [
    "import src.ReccomenderSystem as RC\n",
    "\n",
    "titles = RC.reading_titles('data/game_titles.csv')\n",
    "genres, num_games, num_attributes = RC.reading_votes('data/game_genres.csv')\n",
    "id, taglines = RC.reading_taglines('data/game_tagline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For example, one of the taglines is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(taglines[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Restructuring the data\n",
    "Before we can use scikit-learn to build a classifier, we must make sure that the data is structured in a way scikit-learn will accept.\n",
    "\n",
    "The classifier will take a string as imput and produce a numerical genre index. Below I make a list of all the game tags and a corresponding vector contining all the genre indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_mat = np.zeros((len(id),32))\n",
    "X_mat = []\n",
    "X_titles = []\n",
    "kk = 0;\n",
    "for ii in range(0,len(id)):\n",
    "    tagline_index = np.where(genres[:,0]==int(id[ii]))\n",
    "    if len(tagline_index[0])>0:\n",
    "        X_mat.append(taglines[ii])\n",
    "        for jj in range(0,len(tagline_index[0])):\n",
    "            genre = int(genres[tagline_index[0][jj],1])\n",
    "            y_mat[kk,genre-1] = 1\n",
    "    else:\n",
    "        X_mat.append(taglines[ii])\n",
    "    kk = kk+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploring the data\n",
    "Before I build the classifier, I it is usefull to explore the data to get a realistic expection about how successful the classifier can be. Below I look at how the games are distributed across the different genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "aggregate = sum(y_mat)\n",
    "plt.bar(range(len(aggregate)),aggregate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Many of the genres are empty. That is, there are no games with that genre. There are also quite a few of the genres that have less than 50 games in them. It will be difficult to build a good classifier for there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building my own word tokenizer to take care of stemming\n",
    "I am not sure this is actually used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the classifier using Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "genre_to_train = 0;\n",
    "train_size = int(round(len(y_mat)*0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train = y_mat[0:train_size,genre_to_train]\n",
    "X_train = X_mat[0:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "('vect', TfidfVectorizer(stop_words='english',smooth_idf=1,use_idf=1,analyzer='word')),\n",
    "('tfidf', TfidfTransformer(norm='l2',use_idf=True,smooth_idf=True)),\n",
    "('clf', MultinomialNB())\n",
    "])\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test = X_mat[train_size:-1];\n",
    "y_test = y_mat[train_size:-1,genre_to_train];\n",
    "MultinomialNB_predicted = clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, MultinomialNB_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So answer this question I will loop over all the genres and train and evaluate the classifier. I will save the average precision, recall and f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recall = np.zeros(32)\n",
    "for genre in range(0,32):\n",
    "    y_train = y_mat[0:train_size,genre]\n",
    "    X_train = X_mat[0:train_size]\n",
    "    X_test = X_mat[train_size:-1];\n",
    "    y_test = y_mat[train_size:-1,genre];\n",
    "    if sum(y_train) == 0:\n",
    "        print('No training cases in this class')\n",
    "    elif sum(y_test) == 0:\n",
    "        print('No true samples in the test set')\n",
    "    else:\n",
    "        MultinomialNB_predicted = clf.predict(X_test)\n",
    "        recall[genre] = metrics.recall_score(y_test, MultinomialNB_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0,32),recall)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So quite a few of the genres have 0 recall. This is because there are in fact no gemres in the test set with those genres. If we exclude those we end up with an average recall of;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sum(recall)/sum(recall>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Which is not great, but its not so bad etiher. \n",
    "\n",
    "From here several things could be done:\n",
    "- improve the quality and quantity of the data\n",
    "- Use different and more specific genres\n",
    "- Build better classifier, perhaps tailoring the classifier for each genre\n",
    "- Use more features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Trying out Support Vector as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_SV = Pipeline([\n",
    "('vect', CountVectorizer(stop_words='english')),\n",
    "('tfidf', TfidfTransformer()),\n",
    "('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=10, random_state=42))\n",
    "])\n",
    "\n",
    "recall_SV = np.zeros(32)\n",
    "for genre in range(0,32):\n",
    "    y_train = y_mat[0:train_size,genre]\n",
    "    X_train = X_mat[0:train_size]\n",
    "    X_test = X_mat[train_size:-1];\n",
    "    y_test = y_mat[train_size:-1,genre];\n",
    "    if sum(y_train) == 0:\n",
    "        print('No training cases in this class')\n",
    "    else:\n",
    "        clf_SV = clf_SV.fit(X_train, y_train)\n",
    "        SV_predicted = clf_SV.predict(X_test)\n",
    "        recall_SV[genre] = metrics.recall_score(y_test, SV_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sum(recall_SV)/sum(recall_SV>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0,32),recall_SV)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cool applications of the classifier described above\n",
    "- classify.me: A website that classifies a game given a tagline.\n",
    "- tagline generator: One could run the algorithm in reverse. Given a genre, generate a tagline. I'm not entirely sure how one would do this. The idea is to get some of the top keywords from a genre and then use those to generate a short description. I'm sure other people have worked with generating sentences string from keywords. See eg. [Narrative Science](#https://www.narrativescience.com/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
